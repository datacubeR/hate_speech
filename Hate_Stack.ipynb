{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2256, 9), (2291, 9))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "df_train = pd.read_csv(\"./public_data/tweets_train.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"./Datathon-2022-full/Datos/tweets_test.csv\", index_col=0)\n",
    "stopwords = np.loadtxt(\"public_data/stopwords.txt\", dtype=str)\n",
    "df_train.shape, df_test.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "LABELS = [\n",
    "    \"Odio\",\n",
    "    \"Mujeres\",\n",
    "    \"Comunidad LGBTQ+\",\n",
    "    \"Comunidades Migrantes\",\n",
    "    \"Pueblos Originarios\",\n",
    "]\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=500, random_state=RANDOM_STATE)\n",
    "cb = CatBoostClassifier(n_estimators=500, random_state=RANDOM_STATE, verbose=False)\n",
    "xgb = XGBClassifier(n_estimators=500, random_state=RANDOM_STATE)\n",
    "lr = LogisticRegression(random_state=RANDOM_STATE)\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    alpha=0.1,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición Métrica Competencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def f1_custom(y, y_pred):\n",
    "    y_odio = y[:, 0]\n",
    "    y_pred_odio = y_pred[:, 0]\n",
    "\n",
    "    y_comunidades = y[:, 1:]\n",
    "    y_pred_comunidades = y_pred[:, 1:]\n",
    "\n",
    "    f1_odio = f1_score(y_odio, y_pred_odio)\n",
    "    f1_comunidades = f1_score(y_comunidades, y_pred_comunidades, average=\"macro\")\n",
    "\n",
    "    return 0.5 * f1_odio + 0.5 * f1_comunidades\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [(\"et\", et), (\"cb\", cb), (\"xgb\", xgb), (\"lr\", lr), (\"mlp\", mlp)]\n",
    "\n",
    "hate_stack = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(random_state=42), cv=3\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "def train(df, target_labels):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = []\n",
    "    train_score = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(df[target_labels]), start=1):\n",
    "        X_train = df.iloc[train_idx][\"text\"]\n",
    "        X_val = df.iloc[val_idx][\"text\"]\n",
    "\n",
    "        # Labels are transformed to 0 and 1 if Label is greater than 0.\n",
    "\n",
    "        y_train = df.iloc[train_idx][target_labels].astype(bool).astype(int)\n",
    "        y_val = df.iloc[val_idx][target_labels].astype(bool).astype(int)\n",
    "\n",
    "        # Pipeline Definition\n",
    "        pipe = Pipeline(\n",
    "            [\n",
    "                (\n",
    "                    \"featurizer\",\n",
    "                    CountVectorizer(\n",
    "                        stop_words=list(stopwords),\n",
    "                        lowercase=True,\n",
    "                        ngram_range=(1, 1),\n",
    "                        dtype=np.float32,\n",
    "                    ),\n",
    "                ),\n",
    "                (\"clf\", MultiOutputClassifier(hate_stack)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred_train = pipe.predict(X_train)\n",
    "        y_pred = pipe.predict(X_val)\n",
    "        sc_train = f1_custom(y_train.values, y_pred_train)\n",
    "        sc = f1_custom(y_val.values, y_pred)\n",
    "\n",
    "        # Reporting Results during Training\n",
    "\n",
    "        print(f\"Train Score fold {fold}: {sc_train}\")\n",
    "        print(f\"Validation Score fold {fold}: {sc}\")\n",
    "        print(\"--------------------------------------------\")\n",
    "\n",
    "        train_score.append(sc_train)\n",
    "        score.append(sc)\n",
    "\n",
    "    return train_score, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score fold 1: 0.9992974418134202\n",
      "Validation Score fold 1: 0.770332130752034\n",
      "--------------------------------------------\n",
      "Train Score fold 2: 0.9985402204834405\n",
      "Validation Score fold 2: 0.8071042427462933\n",
      "--------------------------------------------\n",
      "Train Score fold 3: 0.9994154555206065\n",
      "Validation Score fold 3: 0.8061963612916446\n",
      "--------------------------------------------\n",
      "Train Score fold 4: 0.999507874015748\n",
      "Validation Score fold 4: 0.7943036784996272\n",
      "--------------------------------------------\n",
      "Train Score fold 5: 1.0\n",
      "Validation Score fold 5: 0.8177478834597189\n",
      "--------------------------------------------\n",
      "Mean Training Score: 0.9993521983666429\n",
      "Mean Validation Score: 0.7991368593498637\n",
      "CPU times: user 1h 2min 22s, sys: 3min 6s, total: 1h 5min 29s\n",
      "Wall time: 15min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_score, validation_score = train(df_train, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Training Score: 0.9993521983666429\n",
      "Mean Validation Score: 0.7991368593498637\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Training Score: {np.mean(train_score)}\")\n",
    "print(f\"Mean Validation Score: {np.mean(validation_score)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Re-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"cv\",\n",
    "            CountVectorizer(\n",
    "                stop_words=list(stopwords),\n",
    "                lowercase=True,\n",
    "                ngram_range=(1, 1),\n",
    "                dtype=np.float32,\n",
    "            ),\n",
    "        ),\n",
    "        (\"model\", MultiOutputClassifier(hate_stack)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(df_train[\"text\"], df_train[LABELS].astype(\"bool\").astype(\"int\"))\n",
    "y_pred = pipe.predict(df_test[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.8172866645873844\n"
     ]
    }
   ],
   "source": [
    "ground_truth = df_test[LABELS].astype(bool).astype(int)\n",
    "print(f\"Test Score: {f1_custom(ground_truth.values, y_pred)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "675a0b137f74d7d860b3fc58711c736f45facc49eec82aceddc17074e07a94c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
