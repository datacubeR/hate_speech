{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HateStack\n",
    "\n",
    "The following Notebook contain the code of our proposed model: The HateStack. We show the results for the 5-Fold Cross Validation metric (used to determine the generalization power of the model in the competition leaderboard) and the final Test Score measured with the whole Training Data.\n",
    "\n",
    "The evaluation Score used during the competition was a Custom Implementation of the F1-Score defined as:\n",
    "\n",
    "$$F_{1\\,custom} = 0.5 \\cdot (F_{1\\,Hate} + Macro \\, F_{1\\,communities})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-09-15 13:30:55.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.utilities\u001b[0m:\u001b[36mimport_data\u001b[0m:\u001b[36m12\u001b[0m - \u001b[1mTraining and Test data succesfully loaded...\u001b[0m\n",
      "\u001b[32m2023-09-15 13:30:55.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mutils.utilities\u001b[0m:\u001b[36mimport_data\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mTrain Shape: (2256, 9), Test Shape: (2291, 9)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from utils import import_data, validation_train, full_train\n",
    "from sklearn.ensemble import ExtraTreesClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from loguru import logger\n",
    "from pytictoc import TicToc\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "df_train, df_test, stopwords = import_data()\n",
    "\n",
    "LABELS = [\n",
    "    \"Odio\",\n",
    "    \"Mujeres\",\n",
    "    \"Comunidad LGBTQ+\",\n",
    "    \"Comunidades Migrantes\",\n",
    "    \"Pueblos Originarios\",\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=500, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "cb = CatBoostClassifier(\n",
    "    n_estimators=500, thread_count=-1, random_state=RANDOM_STATE, verbose=False\n",
    ")\n",
    "xgb = XGBClassifier(n_estimators=500, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "lr = LogisticRegression(random_state=RANDOM_STATE)\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    alpha=0.1,\n",
    ")\n",
    "\n",
    "estimators = [(\"et\", et), (\"cb\", cb), (\"xgb\", xgb), (\"lr\", lr), (\"mlp\", mlp)]\n",
    "\n",
    "hate_stack = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(random_state=42), cv=3\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Schema\n",
    "\n",
    "Training Process following a 5-Fold Cross Validation Schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score fold 1: 0.9992974418134202\n",
      "Validation Score fold 1: 0.7690925562468738\n",
      "--------------------------------------------\n",
      "Train Score fold 2: 0.9986517262769286\n",
      "Validation Score fold 2: 0.8049551199392759\n",
      "--------------------------------------------\n",
      "Train Score fold 3: 0.9994154555206065\n",
      "Validation Score fold 3: 0.806837224787222\n",
      "--------------------------------------------\n",
      "Train Score fold 4: 0.9997538158542589\n",
      "Validation Score fold 4: 0.796186917671002\n",
      "--------------------------------------------\n",
      "Train Score fold 5: 1.0\n",
      "Validation Score fold 5: 0.8177478834597189\n",
      "--------------------------------------------\n",
      "Stacking Results:\n",
      "Mean Validation Score: 0.7989639404208184\n",
      "SD Validation Score: 0.016436123646685594\n",
      "Mean Precision Validation Score: 0.8790885981248543\n",
      "SD Precision Validation Score: 0.006223935806222798\n",
      "Mean Recall Validation Score: 0.7387118240434579\n",
      "SD Recall Validation Score: 0.02121214078333721\n",
      "HateStack CV Training Time:  553.720891 seconds.\n"
     ]
    }
   ],
   "source": [
    "t = TicToc()\n",
    "t.tic()\n",
    "dict_results = validation_train(\n",
    "    df_train, hate_stack, LABELS, stopwords, random_state=RANDOM_STATE, verbose=True\n",
    ")\n",
    "print(f\"Stacking Results:\")\n",
    "print(f\"Mean Validation Score: {dict_results['mean_val_score']}\")\n",
    "print(f\"SD Validation Score: {dict_results['sd_val_score']}\")\n",
    "print(f\"Mean Precision Validation Score: {dict_results['mean_precision_val_score']}\")\n",
    "print(f\"SD Precision Validation Score: {dict_results['sd_precision_val_score']}\")\n",
    "print(f\"Mean Recall Validation Score: {dict_results['mean_recall_val_score']}\")\n",
    "print(f\"SD Recall Validation Score: {dict_results['sd_recall_val_score']}\")\n",
    "t.toc(\"HateStack CV Training Time: \")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Train and Predictions\n",
    "\n",
    "Test Predictions using the whole Training Set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Results:\n",
      "Test Score: 0.8175373271622297\n",
      "Test Precision: 0.7838088936814132\n",
      "Test Recall: 0.8610952188880378\n",
      "HateStack Full Training Time:  129.480336 seconds.\n"
     ]
    }
   ],
   "source": [
    "t = TicToc()\n",
    "t.tic()\n",
    "dict_results = full_train(df_train, df_test, hate_stack, LABELS, stopwords)\n",
    "print(f\"Stacking Results:\")\n",
    "print(f\"Test Score: {dict_results['test_score']}\")\n",
    "print(f\"Test Precision: {dict_results['test_precision']}\")\n",
    "print(f\"Test Recall: {dict_results['test_recall']}\")\n",
    "t.toc(\"HateStack Full Training Time: \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
